{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: [Lectures 9, 10](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Wednesday, Oct 25, 2021 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    precision_recall_curve,\n",
    "    plot_confusion_matrix,\n",
    "    average_precision_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "- Model A\n",
    "\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 2 | 8 |\n",
    "| **Actual no disease**       | 0 | 100 |\n",
    "\n",
    "\n",
    "- Model B\n",
    "\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 6 | 4 |\n",
    "| **Actual no disease**       | 10 | 90 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"positive\" class is likely to be the case when a patient does have a disease. This is because we are trying to \"spot\" whether a patient has a disease or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is computed by this expression: (TP + TN) / (TN + FP + FN + TP)\n",
    "TP_A = 2\n",
    "FP_A = 0\n",
    "TN_A = 100\n",
    "FN_A = 8\n",
    "\n",
    "TP_B = 6\n",
    "FP_B = 10\n",
    "TN_B = 90\n",
    "FN_B = 4\n",
    "\n",
    "def get_accuracy(TP, FP, TN, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "results_dict[\"A\"][\"accuracy\"] = get_accuracy(TP_A, FP_A, TN_A, FN_A)\n",
    "results_dict[\"B\"][\"accuracy\"] = get_accuracy(TP_B, FP_B, TN_B, FN_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_1(\n",
    "    results_dict[\"A\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_2(\n",
    "    results_dict[\"B\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.872727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A         B\n",
       "accuracy  0.927273  0.872727"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick model A simply based on the accuracy metric since it has higher accuracy than model B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without using `scikit-learn` tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def get_precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def get_f1(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "results_dict[\"A\"][\"precision\"] = get_precision(TP_A, FP_A)\n",
    "results_dict[\"B\"][\"precision\"] = get_precision(TP_B, FP_B)\n",
    "results_dict[\"A\"][\"recall\"] = get_recall(TP_A, FN_A)\n",
    "results_dict[\"B\"][\"recall\"] = get_recall(TP_B, FN_B)\n",
    "results_dict[\"A\"][\"f1\"] = get_f1(results_dict[\"A\"][\"precision\"], results_dict[\"A\"][\"recall\"])\n",
    "results_dict[\"B\"][\"f1\"] = get_f1(results_dict[\"B\"][\"precision\"], results_dict[\"B\"][\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_1(\n",
    "    results_dict[\"A\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_2(\n",
    "    results_dict[\"B\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_3(\n",
    "    results_dict[\"A\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_4(\n",
    "    results_dict[\"B\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_5(\n",
    "    results_dict[\"A\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_6(\n",
    "    results_dict[\"B\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.872727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.927273  0.872727\n",
       "precision  1.000000  0.375000\n",
       "recall     0.200000  0.600000\n",
       "f1         0.333333  0.461538"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Recall is more informative in this problem since the problem is related to medical diagnosis. In medical diagnosis, we do not want to have many false negatives but we do want to ensure that the number of true positives is high among all the positive examples. This is because it is crucial for the classifier to successfully identify positive cases of diseases when they are actually present.\n",
    "    - That being said, we also want to ensure that precision isn't terribly low. For example, recall could be = 1 if we diagnose everyone as positive, but such prediction wouldn't be as meaningful. Therefore, we should still be mindful that precision doesn't drop too low when recall is high.\n",
    "\n",
    "\n",
    "2. Based on the computed metrics along with the response in the answer above, one should pick model B since it has much higher recall than model A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 4 to 5 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of False values:  1984 \n",
      "Number of True values:  349\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of False values: \", np.sum(train_df[\"churn\"] == False), \"\\nNumber of True values: \", np.sum(train_df[\"churn\"] == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes there is class imbalance as there are significantly more `False` values in the `churn` feature compared to `True` values. And yes, we do need to deal with it since the origin of the class imbalance in this scenario is due to the nature that having a value of `True` for the `churn` feature is naturally more rare in the real world. In other words, it is generally more uncommon for subscribers to unsubscribe from a subscription service as opposed to existing subscribers retaining their subscription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:10}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "In each case, briefly explain your rationale with 1-2 sentences. You do not need an explanation for every feature, but for every group of features that are being transformed the same way. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'account length', 'area code', 'phone number',\n",
       "       'international plan', 'voice mail plan', 'number vmail messages',\n",
       "       'total day minutes', 'total day calls', 'total day charge',\n",
       "       'total eve minutes', 'total eve calls', 'total eve charge',\n",
       "       'total night minutes', 'total night calls', 'total night charge',\n",
       "       'total intl minutes', 'total intl calls', 'total intl charge',\n",
       "       'customer service calls', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"state\", \"area code\"]\n",
    "numerical_features = [\n",
    "    \"account length\",\n",
    "    \"number vmail messages\",\n",
    "    \"total day minutes\", \"total day calls\", \"total day charge\",\n",
    "    \"total eve minutes\", \"total eve calls\", \"total eve charge\",\n",
    "    \"total night minutes\", \"total night calls\", \"total night charge\",\n",
    "    \"total intl minutes\", \"total intl calls\", \"total intl charge\",\n",
    "    \"customer service calls\",\n",
    "]\n",
    "binary_features = [\"international plan\", \"voice mail plan\"]\n",
    "ordinal_features = []\n",
    "passthrough_features = []\n",
    "drop_features = [\"phone number\"] # drop phone number b/c each row in training data corresponds to exactly one unique phone number\n",
    "\n",
    "# define transformers\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "numerical_transformer = StandardScaler()\n",
    "binary_transformer = OneHotEncoder(drop=\"if_binary\")\n",
    "\n",
    "# define ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (numerical_transformer, numerical_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (binary_transformer, binary_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove\n",
    "len(train_df[\"phone number\"].unique()) == len(train_df)\n",
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"state\" and \"area code\" features are categorical since they have a finite set of values that can be considered categories and they have no ordinal nature.\n",
    "\n",
    "The \"account length\", \"number vmail messages\" and all the features related to the number of minutes, calls, and charges, are all considered numerical since they hold numeric values.\n",
    "\n",
    "The \"international plan\" and \"voice mail plan\" features are binary features since they only hold the values \"yes\" and \"no\".\n",
    "\n",
    "The \"phone number\" feature can be dropped since each row in the training data corresponds to exactly one unique phone number so this feature would not be useful when fitting the model.\n",
    "\n",
    "// todo: add why we dropped phone and vmail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the transformed data \n",
    "rubric={points:4}\n",
    "\n",
    "Fit and transform your `ColumnTransformer` on your training set. Print the first 5 rows of the transformed data as a dataframe (not numpy array). See lecture 10 for code that can get you the new column names after transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop': 'drop',\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'onehotencoder-1': OneHotEncoder(handle_unknown='ignore', sparse=False),\n",
       " 'onehotencoder-2': OneHotEncoder(drop='if_binary')}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_train)\n",
    "preprocessor.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>...</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>area code_408</th>\n",
       "      <th>area code_415</th>\n",
       "      <th>area code_510</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>-0.767893</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>-0.721211</td>\n",
       "      <td>0.618927</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>-1.156734</td>\n",
       "      <td>0.069926</td>\n",
       "      <td>1.088667</td>\n",
       "      <td>0.052115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>-0.843585</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-1.293778</td>\n",
       "      <td>1.655252</td>\n",
       "      <td>-1.293517</td>\n",
       "      <td>-1.167277</td>\n",
       "      <td>-1.207278</td>\n",
       "      <td>-1.166291</td>\n",
       "      <td>-2.162302</td>\n",
       "      <td>-0.720990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.544113</td>\n",
       "      <td>1.900976</td>\n",
       "      <td>-0.609809</td>\n",
       "      <td>0.169963</td>\n",
       "      <td>-0.609654</td>\n",
       "      <td>-2.210130</td>\n",
       "      <td>0.157417</td>\n",
       "      <td>-2.211244</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>-0.463288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.165650</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>-0.473663</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>-0.754894</td>\n",
       "      <td>0.258506</td>\n",
       "      <td>-0.755774</td>\n",
       "      <td>1.597736</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-0.994886</td>\n",
       "      <td>0.764078</td>\n",
       "      <td>-0.994731</td>\n",
       "      <td>1.195994</td>\n",
       "      <td>-0.246937</td>\n",
       "      <td>1.196515</td>\n",
       "      <td>0.793839</td>\n",
       "      <td>0.206736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account length  number vmail messages  total day minutes  \\\n",
       "1402       -0.767893              -0.587624           0.618769   \n",
       "1855       -0.843585              -0.587624          -1.293778   \n",
       "633         0.544113               1.900976          -0.609809   \n",
       "1483        0.165650              -0.587624           0.998345   \n",
       "2638        0.115188              -0.587624          -0.994886   \n",
       "\n",
       "      total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "1402        -0.721211          0.618927           0.069871        -1.156734   \n",
       "1855         1.655252         -1.293517          -1.167277        -1.207278   \n",
       "633          0.169963         -0.609654          -2.210130         0.157417   \n",
       "1483        -0.473663          0.998611          -0.754894         0.258506   \n",
       "2638         0.764078         -0.994731           1.195994        -0.246937   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  ...  state_VT  \\\n",
       "1402          0.069926             1.088667           0.052115  ...       0.0   \n",
       "1855         -1.166291            -2.162302          -0.720990  ...       0.0   \n",
       "633          -2.211244             0.369287          -0.463288  ...       0.0   \n",
       "1483         -0.755774             1.597736           0.000574  ...       0.0   \n",
       "2638          1.196515             0.793839           0.206736  ...       0.0   \n",
       "\n",
       "      state_WA  state_WI  state_WV  state_WY  area code_408  area code_415  \\\n",
       "1402       0.0       0.0       0.0       0.0            0.0            1.0   \n",
       "1855       0.0       1.0       0.0       0.0            0.0            0.0   \n",
       "633        0.0       0.0       0.0       0.0            0.0            1.0   \n",
       "1483       0.0       0.0       0.0       0.0            0.0            0.0   \n",
       "2638       0.0       0.0       0.0       0.0            0.0            0.0   \n",
       "\n",
       "      area code_510  international plan  voice mail plan  \n",
       "1402            0.0                 0.0              0.0  \n",
       "1855            1.0                 0.0              0.0  \n",
       "633             0.0                 0.0              1.0  \n",
       "1483            1.0                 1.0              0.0  \n",
       "2638            1.0                 0.0              0.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_columns = list(\n",
    "    preprocessor.named_transformers_[\"onehotencoder-1\"]\n",
    "    .get_feature_names(categorical_features)\n",
    ")\n",
    "binary_cols = list(\n",
    "    preprocessor.named_transformers_[\"onehotencoder-2\"]\n",
    "    .get_feature_names(binary_features)\n",
    ")\n",
    "new_columns = numerical_features + ohe_columns + binary_features\n",
    "\n",
    "X_train_transformed = pd.DataFrame(\n",
    "    preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    ")\n",
    "X_train_transformed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`. Let's assume we encoded this feature with one-hot encoding.\n",
    "\n",
    "1. The area codes were numbers to begin with. Why do we want to use one-hot encoding on this feature?\n",
    "2. What were the possible values of `area code`? \n",
    "3. What new feature(s) were created to replace `area code`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([415, 510, 408])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"area code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We want to use one-hot encoding on the \"area code\" feature b/c as seen in the cell above, it only holds a set of 3 unique possible values which can be considered distinct categories as they can be used to help group the training data.\n",
    "2. The possible values of \"area code\" are `415, 510` and `408`.\n",
    "3. The new feature names that were created to replace \"area code\" are `area code_408, area code_415` and `area code_510`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Dummy classifier\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Create a `DummyClassifier`. Report the following scoring metrics via cross-validation: accuracy, precision, recall, f1-score. Briefly comment on your results, including any warnings the code produces (2 sentences max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jpan/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jpan/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jpan/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jpan/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jpan/miniconda3/envs/cpsc330/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.851931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_f1  test_recall  test_precision\n",
       "0  0.001929    0.007905       0.850107      0.0          0.0             0.0\n",
       "1  0.001749    0.003709       0.850107      0.0          0.0             0.0\n",
       "2  0.001600    0.003615       0.850107      0.0          0.0             0.0\n",
       "3  0.001428    0.004355       0.851931      0.0          0.0             0.0\n",
       "4  0.001773    0.003602       0.849785      0.0          0.0             0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmy_classifier = DummyClassifier()\n",
    "\n",
    "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
    "pd.DataFrame(cross_validate(dmy_classifier, X_train, y_train, scoring=scoring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model produced a fairly high accuracy. However, considering that dummy classifier predicts the most frequently-occurring target value _and_ in our example, False dominates True as targets, it makes sense that by predicting False, the dummy classifier would be able to get the majority of the predictions correct.\n",
    "\n",
    "The warning produced by the code was:\n",
    "```\n",
    "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "```\n",
    "This was caused by the precision calculation. Since the dummy classifier generated all negative prediction, there were no positive predictions, making TP and FP = 0 while TN and FN > 0. \n",
    "Precision = TP / (TP + FP) -> in this case, the numerator and denominator are both 0. Dividing by 0 is what caused the error.\n",
    "\n",
    "Recall is 0 because TP = 0 is in the numerator. With recall = 0, even if precision was valid, f1 would also be 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Logistic regression\n",
    "rubric={points:8} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train and score a logistic regression classifier on the dataset. \n",
    "2. Report the same metrics as in the previous part.\n",
    "3. Are you satisfied with the results? Use your `DummyClassifier` results as a reference point. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110564</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.869379</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.114110</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081792</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073404</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080017</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>0.839056</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy   test_f1  test_recall  test_precision\n",
       "0  0.110564    0.013654       0.869379  0.371134     0.257143        0.666667\n",
       "1  0.114110    0.029773       0.852248  0.273684     0.185714        0.520000\n",
       "2  0.081792    0.011798       0.850107  0.255319     0.171429        0.500000\n",
       "3  0.073404    0.013771       0.869099  0.371134     0.260870        0.642857\n",
       "4  0.080017    0.013467       0.839056  0.242424     0.171429        0.413793"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression())\n",
    "pd.DataFrame(cross_validate(pipe_lr, X_train, y_train, scoring=scoring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not satisfied with the results as the observed validation recall is quite low. \n",
    "\n",
    "\n",
    "Recall is more important because we want to be able to detect potential churn (i.e. people who want to leave) so we can act on it before they leave. In this case, having more positive predictions also doesn't hurt the customer very much (because they could just be getting more marketing material), so precision is not as important.\n",
    "\n",
    "Therefore, although the precision is high, a low validation recall is why we are not satisfied. However, it is certainly better than the results produced by the DummyClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098768</td>\n",
       "      <td>0.014897</td>\n",
       "      <td>0.785867</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099640</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>0.768737</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111183</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.764454</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.348485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075338</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy   test_f1  test_recall  test_precision\n",
       "0  0.098768    0.014897       0.785867  0.489796     0.685714        0.380952\n",
       "1  0.099640    0.017723       0.768737  0.490566     0.742857        0.366197\n",
       "2  0.111183    0.015706       0.764454  0.455446     0.657143        0.348485\n",
       "3  0.075338    0.013546       0.751073  0.462963     0.724638        0.340136\n",
       "4  0.092931    0.013273       0.733906  0.436364     0.685714        0.320000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr_balanced = make_pipeline(preprocessor, LogisticRegression(class_weight=\"balanced\"))\n",
    "pd.DataFrame(cross_validate(pipe_lr_balanced, X_train, y_train, scoring=scoring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we prefer this model over the one in the previous part as it produces significantly higher validation recall. As mentioned before, recall is a more important metric to look at because churn (positive predictions) is what we want to spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "Now let's tune the hyperparameters of our `LogisticRegression` using `GridSearchCV` to maximize cross-validation f1 score. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Jointly optimize `C` (choose some reasonable values) and `class_weight` (`None` vs. `'balanced'`) with `GridSearchCV` and `scoring=\"f1\"`. \n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('drop',\n",
       "                                                                         'drop',\n",
       "                                                                         ['phone '\n",
       "                                                                          'number']),\n",
       "                                                                        ('standardscaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['account '\n",
       "                                                                          'length',\n",
       "                                                                          'number '\n",
       "                                                                          'vmail '\n",
       "                                                                          'messages',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'night...\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                       sparse=False),\n",
       "                                                                         ['state',\n",
       "                                                                          'area '\n",
       "                                                                          'code']),\n",
       "                                                                        ('onehotencoder-2',\n",
       "                                                                         OneHotEncoder(drop='if_binary'),\n",
       "                                                                         ['international '\n",
       "                                                                          'plan',\n",
       "                                                                          'voice '\n",
       "                                                                          'mail '\n",
       "                                                                          'plan'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         'logisticregression__class_weight': [None,\n",
       "                                                              'balanced']},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__C\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "    \"logisticregression__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "pipe_lr_grid = make_pipeline(preprocessor, LogisticRegression())\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipe_lr_grid, param_grid, cv=5, n_jobs=-1, return_train_score=True, scoring=\"f1\"\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best cross-validation f1 score is:  0.47873599874436196\n"
     ]
    }
   ],
   "source": [
    "print(\"The best cross-validation f1 score is: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Confusion matrix. \n",
    "    - Classification report. \n",
    "    - Precision-recall curve with average precision score.     \n",
    "    - ROC curve with AUC. \n",
    "3. Comment on the results.    \n",
    "\n",
    "> Note that we are not doing it here but in real life, you would also plot confusion matrix, precision-recall curve, and ROC curve on validation data to examine errors and to choose a threshold which works for your operating point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2887fc0dcd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(grid_search, X_test, y_test, display_labels=[\"not churned\", \"churned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " not churned       0.95      0.77      0.85       866\n",
      "     churned       0.34      0.76      0.47       134\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.65      0.77      0.66      1000\n",
      "weighted avg       0.87      0.77      0.80      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_test, grid_search.predict(X_test), target_names=[\"not churned\", \"churned\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28802153d30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, grid_search.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, grid_search.predict(X_test)),\n",
    "    recall_score(y_test, grid_search.predict(X_test)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision of logistic regression: 0.456\n"
     ]
    }
   ],
   "source": [
    "ap_lr = average_precision_score(y_test, grid_search.predict_proba(X_test)[:, 1])\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, grid_search.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider \"churned\" to be the positive class.\n",
    "\n",
    "From the classification report, it can then be observed that the precision is 0.34, recall is 0.76, and f1-score is 0.47. The best grid searched logistic regression model had decent recall but poor precision and f1-score. This means the model performed decently in identifying the positive examples but also had many misclassifications.\n",
    "\n",
    "Based on the precision-recall curve, we can observe that across multiple threshold values, the model is not very good at maximizing both precision and recall and the tradeoff is steep. This is because there is no point on the curve that is close to the top-right corner. The average precision value also sits roughly in the middle and is not great.\n",
    "\n",
    "Based on the ROC curve, we observe a similar result as the precision-recall curve where there is no point on the curve that is optimal (e.g. close to the top-left corner). This indicates that it's difficult for the model to obtain high recall while maintaining a low false positive rate. This can also be confirmed from the first paragraph summarizing the results of the classification report in that the model achieved decent recall but poor precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (80%) and test (20%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` in train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_house_df, test_house_df = train_test_split(housing_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_house_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>4.5694</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.219512</td>\n",
       "      <td>1.030488</td>\n",
       "      <td>504.0</td>\n",
       "      <td>3.073171</td>\n",
       "      <td>38.38</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>5.6392</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.951644</td>\n",
       "      <td>1.034816</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>2.911025</td>\n",
       "      <td>34.26</td>\n",
       "      <td>-118.60</td>\n",
       "      <td>2.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>1.7292</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.628032</td>\n",
       "      <td>1.032345</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>3.913747</td>\n",
       "      <td>34.07</td>\n",
       "      <td>-118.21</td>\n",
       "      <td>1.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>4.6226</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.126238</td>\n",
       "      <td>0.985149</td>\n",
       "      <td>988.0</td>\n",
       "      <td>2.445545</td>\n",
       "      <td>33.96</td>\n",
       "      <td>-118.02</td>\n",
       "      <td>2.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>2.4375</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.024390</td>\n",
       "      <td>0.942073</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>4.283537</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-118.20</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "9950  4.5694      28.0  6.219512   1.030488       504.0  3.073171     38.38   \n",
       "3547  5.6392      18.0  5.951644   1.034816      3010.0  2.911025     34.26   \n",
       "4448  1.7292      47.0  3.628032   1.032345      1452.0  3.913747     34.07   \n",
       "6984  4.6226      36.0  5.126238   0.985149       988.0  2.445545     33.96   \n",
       "4432  2.4375      49.0  4.024390   0.942073      1405.0  4.283537     34.08   \n",
       "\n",
       "      Longitude  MedHouseVal  \n",
       "9950    -122.33        2.875  \n",
       "3547    -118.60        2.715  \n",
       "4448    -118.21        1.917  \n",
       "6984    -118.02        2.197  \n",
       "4432    -118.20        1.140  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_house_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the features have null/empty values and they are also all numerical features. Thus, we only need to apply a StandardScaler on all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_house = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_house, y_train_house = train_house_df.drop(columns=[\"MedHouseVal\"]), train_house_df[\"MedHouseVal\"]\n",
    "X_test_house, y_test_house = test_house_df.drop(columns=[\"MedHouseVal\"]), test_house_df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: DummyRegressor \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `DummyRegressor` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>-0.001050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.005182    0.000318   -0.001675          0.0\n",
       "1  0.003505    0.000667   -0.001050          0.0\n",
       "2  0.002469    0.001007   -0.000509          0.0\n",
       "3  0.002397    0.000000   -0.000349          0.0\n",
       "4  0.001760    0.001001   -0.000663          0.0\n",
       "5  0.002759    0.000753   -0.001729          0.0\n",
       "6  0.002532    0.001005   -0.000094          0.0\n",
       "7  0.002170    0.000437   -0.000008          0.0\n",
       "8  0.001770    0.001002   -0.000222          0.0\n",
       "9  0.001784    0.000000   -0.000802          0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(DummyRegressor(), X_train_house, y_train_house, cv=10, return_train_score=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ metric is used for scoring by default for DummyRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Different regressors\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for different regressors (`models`) and different scoring metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <th>train_mape_scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.543796</td>\n",
       "      <td>-0.523434</td>\n",
       "      <td>-0.737425</td>\n",
       "      <td>-0.723487</td>\n",
       "      <td>-0.537722</td>\n",
       "      <td>-0.530319</td>\n",
       "      <td>0.600728</td>\n",
       "      <td>0.604798</td>\n",
       "      <td>-32.879669</td>\n",
       "      <td>-31.565152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>-0.523154</td>\n",
       "      <td>-0.526913</td>\n",
       "      <td>-0.723294</td>\n",
       "      <td>-0.725888</td>\n",
       "      <td>-0.538830</td>\n",
       "      <td>-0.531133</td>\n",
       "      <td>0.609386</td>\n",
       "      <td>0.603822</td>\n",
       "      <td>-31.382857</td>\n",
       "      <td>-31.924930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010235</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>-0.530828</td>\n",
       "      <td>-0.524935</td>\n",
       "      <td>-0.728579</td>\n",
       "      <td>-0.724524</td>\n",
       "      <td>-0.529630</td>\n",
       "      <td>-0.533808</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.603422</td>\n",
       "      <td>-31.636865</td>\n",
       "      <td>-31.937245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012812</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>-0.526309</td>\n",
       "      <td>-0.526141</td>\n",
       "      <td>-0.725472</td>\n",
       "      <td>-0.725356</td>\n",
       "      <td>-0.534463</td>\n",
       "      <td>-0.532982</td>\n",
       "      <td>0.599991</td>\n",
       "      <td>0.606191</td>\n",
       "      <td>-31.977278</td>\n",
       "      <td>-31.841225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>-1.293077</td>\n",
       "      <td>-0.520423</td>\n",
       "      <td>-1.137135</td>\n",
       "      <td>-0.721403</td>\n",
       "      <td>-0.536574</td>\n",
       "      <td>-0.528700</td>\n",
       "      <td>-0.012554</td>\n",
       "      <td>0.613268</td>\n",
       "      <td>-32.021087</td>\n",
       "      <td>-31.546342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  0.022318    0.003409                    -0.543796   \n",
       "1  0.008989    0.003828                    -0.523154   \n",
       "2  0.010235    0.003859                    -0.530828   \n",
       "3  0.012812    0.005015                    -0.526309   \n",
       "4  0.010170    0.004344                    -1.293077   \n",
       "\n",
       "   train_neg_mean_squared_error  test_neg_root_mean_squared_error  \\\n",
       "0                     -0.523434                         -0.737425   \n",
       "1                     -0.526913                         -0.723294   \n",
       "2                     -0.524935                         -0.728579   \n",
       "3                     -0.526141                         -0.725472   \n",
       "4                     -0.520423                         -1.137135   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
       "0                          -0.723487                     -0.537722   \n",
       "1                          -0.725888                     -0.538830   \n",
       "2                          -0.724524                     -0.529630   \n",
       "3                          -0.725356                     -0.534463   \n",
       "4                          -0.721403                     -0.536574   \n",
       "\n",
       "   train_neg_mean_absolute_error   test_r2  train_r2  test_mape_scorer  \\\n",
       "0                      -0.530319  0.600728  0.604798        -32.879669   \n",
       "1                      -0.531133  0.609386  0.603822        -31.382857   \n",
       "2                      -0.533808  0.611168  0.603422        -31.636865   \n",
       "3                      -0.532982  0.599991  0.606191        -31.977278   \n",
       "4                      -0.528700 -0.012554  0.613268        -32.021087   \n",
       "\n",
       "   train_mape_scorer  \n",
       "0         -31.565152  \n",
       "1         -31.924930  \n",
       "2         -31.937245  \n",
       "3         -31.841225  \n",
       "4         -31.546342  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pipe = make_pipeline(preprocessor_house, models[\"Ridge\"])\n",
    "pd.DataFrame(\n",
    "    cross_validate(\n",
    "        ridge_pipe,\n",
    "        X_train_house,\n",
    "        y_train_house,\n",
    "        return_train_score=True,\n",
    "        scoring=score_types_reg,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <th>train_mape_scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.555601</td>\n",
       "      <td>0.102588</td>\n",
       "      <td>-0.248925</td>\n",
       "      <td>-0.038710</td>\n",
       "      <td>-0.498924</td>\n",
       "      <td>-0.196748</td>\n",
       "      <td>-0.333200</td>\n",
       "      <td>-0.127561</td>\n",
       "      <td>0.817231</td>\n",
       "      <td>0.970773</td>\n",
       "      <td>-19.679852</td>\n",
       "      <td>-7.201208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.810642</td>\n",
       "      <td>0.128097</td>\n",
       "      <td>-0.259736</td>\n",
       "      <td>-0.035451</td>\n",
       "      <td>-0.509643</td>\n",
       "      <td>-0.188283</td>\n",
       "      <td>-0.330100</td>\n",
       "      <td>-0.122609</td>\n",
       "      <td>0.806067</td>\n",
       "      <td>0.973345</td>\n",
       "      <td>-17.875438</td>\n",
       "      <td>-6.934919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.940460</td>\n",
       "      <td>0.281928</td>\n",
       "      <td>-0.258510</td>\n",
       "      <td>-0.037006</td>\n",
       "      <td>-0.508439</td>\n",
       "      <td>-0.192369</td>\n",
       "      <td>-0.330220</td>\n",
       "      <td>-0.126462</td>\n",
       "      <td>0.810641</td>\n",
       "      <td>0.972043</td>\n",
       "      <td>-18.453653</td>\n",
       "      <td>-7.179364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.723404</td>\n",
       "      <td>0.096846</td>\n",
       "      <td>-0.284244</td>\n",
       "      <td>-0.036369</td>\n",
       "      <td>-0.533145</td>\n",
       "      <td>-0.190706</td>\n",
       "      <td>-0.346514</td>\n",
       "      <td>-0.124670</td>\n",
       "      <td>0.783967</td>\n",
       "      <td>0.972779</td>\n",
       "      <td>-19.451462</td>\n",
       "      <td>-7.012307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.702656</td>\n",
       "      <td>0.166808</td>\n",
       "      <td>-0.262470</td>\n",
       "      <td>-0.036026</td>\n",
       "      <td>-0.512319</td>\n",
       "      <td>-0.189805</td>\n",
       "      <td>-0.331750</td>\n",
       "      <td>-0.123331</td>\n",
       "      <td>0.794470</td>\n",
       "      <td>0.973229</td>\n",
       "      <td>-18.930323</td>\n",
       "      <td>-6.950194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0   9.555601    0.102588                    -0.248925   \n",
       "1   9.810642    0.128097                    -0.259736   \n",
       "2  10.940460    0.281928                    -0.258510   \n",
       "3   9.723404    0.096846                    -0.284244   \n",
       "4  10.702656    0.166808                    -0.262470   \n",
       "\n",
       "   train_neg_mean_squared_error  test_neg_root_mean_squared_error  \\\n",
       "0                     -0.038710                         -0.498924   \n",
       "1                     -0.035451                         -0.509643   \n",
       "2                     -0.037006                         -0.508439   \n",
       "3                     -0.036369                         -0.533145   \n",
       "4                     -0.036026                         -0.512319   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
       "0                          -0.196748                     -0.333200   \n",
       "1                          -0.188283                     -0.330100   \n",
       "2                          -0.192369                     -0.330220   \n",
       "3                          -0.190706                     -0.346514   \n",
       "4                          -0.189805                     -0.331750   \n",
       "\n",
       "   train_neg_mean_absolute_error   test_r2  train_r2  test_mape_scorer  \\\n",
       "0                      -0.127561  0.817231  0.970773        -19.679852   \n",
       "1                      -0.122609  0.806067  0.973345        -17.875438   \n",
       "2                      -0.126462  0.810641  0.972043        -18.453653   \n",
       "3                      -0.124670  0.783967  0.972779        -19.451462   \n",
       "4                      -0.123331  0.794470  0.973229        -18.930323   \n",
       "\n",
       "   train_mape_scorer  \n",
       "0          -7.201208  \n",
       "1          -6.934919  \n",
       "2          -7.179364  \n",
       "3          -7.012307  \n",
       "4          -6.950194  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_pipe = make_pipeline(preprocessor_house, models[\"Random Forest\"])\n",
    "pd.DataFrame(\n",
    "    cross_validate(\n",
    "        random_forest_pipe,\n",
    "        X_train_house,\n",
    "        y_train_house,\n",
    "        return_train_score=True,\n",
    "        scoring=score_types_reg,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of negative mean squared error, the RandomForestRegressor performed nearly twice as well as the RidgeRegressor on the validation data since its `test_neg_mean_squared_error` value is twice as close to 0 as that of the RidgeRegreessor. The RandomForestRegressor also performed very well on the training data while the RidgeRegressor performed similarly poor on both the training and validation data.\n",
    "\n",
    "In terms of the negative root mean squared error, the RandomForestRegressor also performed better than the RidgeRegressor as its values are closer to 0. However, the values are still quite far from 0 which means none of the models did a good job on the validation data.\n",
    "\n",
    "Based on the MAPE scores and $R^2$ scores, the RandomForestRegressor also performed better on both the validation and training data.\n",
    "\n",
    "Thus, with a comparison of the different scores, it appears that the RandomForestRegressor performs better across different metrics. Both models also perform significantly better than the baseline DummyRegressor model as their $R^2$ scores are much higher.\n",
    "\n",
    "TODO: figure out how to interpret negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose the metric of your choice for hyperparameter optimization. \n",
    "2. Are you getting better scores compared to the default values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try the best model on the test set.\n",
    "2. Briefly comment on the results. (1 to 2 sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8109948390177858"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_pipe.fit(X_train_house, y_train_house)\n",
    "random_forest_pipe.score(X_test_house, y_test_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the default scoring method of the RandomForestRegressor is also $R^2$, then we can compare the $R^2$ scores between the test results and validation results. The score produced on the test set is similar to the scores produced on the validation data which means this model will likely generalize in a similar manner to further unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: features and coefficients. If you attempted 3.4, use the `Ridge` model with best hyperparameters. Otherwise use the `Ridge` model with default hyperparameters. \n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.835964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>0.318049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.115302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>-0.007375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.281707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.854789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.889398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "0      MedInc      0.835964\n",
       "3   AveBedrms      0.318049\n",
       "1    HouseAge      0.115302\n",
       "4  Population     -0.007375\n",
       "5    AveOccup     -0.041683\n",
       "2    AveRooms     -0.281707\n",
       "7   Longitude     -0.854789\n",
       "6    Latitude     -0.889398"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pipe.fit(X_train_house, y_train_house)\n",
    "feature_coefs_df = pd.DataFrame({\n",
    "    \"features\": X_train_house.columns,\n",
    "    \"coefficients\": ridge_pipe.named_steps[\"ridge\"].coef_,\n",
    "})\n",
    "feature_coefs_df.sort_values(\"coefficients\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the feature values of features with positive coefficients will result in a higher housing price. Based on the results above, these features are `MedInc`, `AveBedrms`, and `HouseAge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
